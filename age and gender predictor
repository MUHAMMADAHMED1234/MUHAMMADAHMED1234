from os import listdir
from os.path import isdir
from PIL import Image
from matplotlib import pyplot
from numpy import savez_compressed
from numpy import asarray
from mtcnn.mtcnn import MTCNN
from numpy import load
from numpy import expand_dims
from keras.models import load_model
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import Normalizer
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import cv2
import numpy as np
import os
from tkinter import filedialog
from tkinter import Tk
import sys

detector = MTCNN() # Multitask Convolutional Neural Network
# extract a single face from a given photograph
def extract_face(filename, required_size=(160, 160)):
	# load image from file
	#print('image:',filename);
	image = Image.open(filename)
	image_copy = image
	# convert to RGB, if needed
	image = image.convert('RGB')
	# convert to array
	pixels = asarray(image)
	# detect faces in the image
	results = detector.detect_faces(pixels)
	# extract the bounding box from the first face
	x1, y1, width, height = results[0]['box']
	# bug fix
	x1, y1 = abs(x1), abs(y1)
	x2, y2 = x1 + width, y1 + height    
	# extract the face
	face = pixels[y1:y2, x1:x2]
	# resize pixels to the model size
	image = Image.fromarray(face)
	image = image.resize(required_size)
	face_array = asarray(image)
	return face_array, image_copy

# extract a single face from a given photograph
def extract_face2(filename, required_size=(160, 160)):
	# load image from file
	#print('image:',filename);
	image = filename
	#image_copy = image
	# convert to RGB, if needed
	#image = image.convert('RGB')
	# convert to array
	pixels = asarray(image)
	# detect faces in the image
	results = detector.detect_faces(pixels)
	# extract the bounding box from the first face
	x1, y1, width, height = results[0]['box']
	# bug fix
	x1, y1 = abs(x1), abs(y1)
	x2, y2 = x1 + width, y1 + height    
	# extract the face
	face = pixels[y1:y2, x1:x2]
	# resize pixels to the model size
	image = Image.fromarray(face)
	image = image.resize(required_size)
	face_array = asarray(image)
	return face_array
 
# load images and extract faces for all images in a directory
def load_faces(directory):
	faces = list()
	# enumerate files
	for filename in listdir(directory):
		# path
		path = directory + filename
		# get face
		face = extract_face(path)
		# store
		faces.append(face)
	return faces
 
# load a dataset that contains one subdir for each class that in turn contains images
def load_dataset_new_path(directory):
    gender_faces, gender_labels, age_groups,  = list(), list(), list()
    # enumerate folders, on per class
    for subdir in listdir(directory):
        path = directory + subdir + '/'
        print('loading class: ', subdir)
        for p in listdir(path):
            path = directory + subdir + '/'+ p + '/'
            #print(path)
            # skip any files that might be in the dir
            if not isdir(path):
                continue
            # load all faces in the subdirectory
            faces = load_faces(path)
            #create labels
            labels = [subdir for _ in range(len(faces))]
            groups = [p for _ in range(len(faces))]
            # summarize progress
            print('>loaded %d examples: %s' % (len(faces), p))
            # store
            gender_faces.extend(faces)
            gender_labels.extend(labels)
            age_groups.extend(groups)
    return asarray(gender_faces), asarray(gender_labels), asarray(gender_faces), asarray(age_groups)
# load train dataset
trainFaces, trainFaceLabels, trainAgeGroupFaces, trainAgeGroupLabels = load_dataset_new_path('c:/dl_research/age_gender_detection/dataset3/train/')
# load test dataset
testFaces, testFaceLabels, testAgeGroupFaces, testAgeGroupLabels = load_dataset_new_path('c:/dl_research/age_gender_detection/dataset3/val/')
#save arrays to one file in compressed format
savez_compressed('c:/dl_research/age_gender_detection/dataset3.npz', trainFaces, trainFaceLabels, testFaces, testFaceLabels, trainAgeGroupFaces, trainAgeGroupLabels, testAgeGroupFaces, testAgeGroupLabels)
print(trainFaces.shape, trainFaceLabels.shape, trainAgeGroupFaces.shape, trainAgeGroupLabels.shape)
print(testFaces.shape, testFaceLabels.shape, testAgeGroupFaces.shape, testAgeGroupLabels.shape)
# get the face embedding for one face
def get_embedding(model, face_pixels):
	# scale pixel values
	face_pixels = face_pixels.astype('float32')
	# standardize pixel values across channels (global)
	mean, std = face_pixels.mean(), face_pixels.std()
	face_pixels = (face_pixels - mean) / std
	# transform face into one sample
	samples = expand_dims(face_pixels, axis=0)
	# make prediction to get embedding
	pred = model.predict(samples)
	return pred[0]
# load the face dataset
data = load('c:/dl_research/age_gender_detection/dataset3.npz')
trainFaces, trainFaceLabels, testFaces, testFaceLabels, trainAgeGroupFaces, trainAgeGroupLabels, testAgeGroupFaces, testAgeGroupLabels = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5'], data['arr_6'], data['arr_7']
print('Loaded: ', trainFaces.shape, trainFaceLabels.shape, testFaces.shape, testFaceLabels.shape, trainAgeGroupFaces.shape, trainAgeGroupLabels.shape, testAgeGroupFaces.shape, testAgeGroupLabels.shape)
model = load_model('c:/dl_research/age_gender_detection/models/facenet_keras.h5')
#model = VGGFace()
print('Loaded Model')
# convert each face in the train set to an embedding
newTrainFaces = list()
for face_pixels in trainFaces:
	embedding = get_embedding(model, face_pixels)
	newTrainFaces.append(embedding)
newTrainFaces = asarray(newTrainFaces)
print('training faces: ', newTrainFaces.shape)

newTrainAgeGroupFaces = list()
for face_pixels in trainFaces:
	embedding = get_embedding(model, face_pixels)
	newTrainAgeGroupFaces.append(embedding)
newTrainAgeGroupFaces = asarray(newTrainAgeGroupFaces)
print('training age groups faces: ', newTrainAgeGroupFaces.shape)

# convert each face in the test set to an embedding
newTestFaces = list()
for face_pixels in testFaces:
	embedding = get_embedding(model, face_pixels)
	newTestFaces.append(embedding)
newTestFaces = asarray(newTestFaces)
print('test faces: ', newTestFaces.shape)

newTestAgeGroupFaces = list()
for face_pixels in testFaces:
	embedding = get_embedding(model, face_pixels)
	newTestAgeGroupFaces.append(embedding)
newTestAgeGroupFaces = asarray(newTestAgeGroupFaces)
print('test age group faces: ', newTestAgeGroupFaces.shape)

# save arrays to one file in compressed format
savez_compressed('c:/dl_research/age_gender_detection/faces_embeddings3.npz', newTrainFaces, trainFaceLabels, newTestFaces, testFaceLabels, newTrainAgeGroupFaces, trainAgeGroupLabels, newTestAgeGroupFaces, testAgeGroupLabels)
# load dataset
data = load('c:/dl_research/age_gender_detection/faces_embeddings3.npz')
trainFaces, trainFaceLabels, testFaces, testFaceLabels, trainAgeGroupFaces, trainAgeGroupLabels, testAgeGroupFaces, testAgeGroupLabels = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5'], data['arr_6'], data['arr_7'] 
#print('Dataset: trainFaces=%d, testFaces=%d, trainAgeGroupFaces=%d, testAgeGroupFaces=%d,' % (trainFaces.shape[0], testFaces.shape[0], trainAgeGroupFaces.shape[0], testAgeGroupFaces[0]))
#normalize input vectors

gender_encoder = Normalizer(norm='l2')
trainFaces = gender_encoder.transform(trainFaces)
testFaces = gender_encoder.transform(testFaces)

age_encoder = Normalizer(norm='l2')
trainAgeGroupFaces = age_encoder.transform(trainAgeGroupFaces)
testAgeGroupFaces = age_encoder.transform(testAgeGroupFaces)

# label encode targets
gender_encoder = LabelEncoder()
gender_encoder.fit(trainFaceLabels)
trainFaceLabels = gender_encoder.transform(trainFaceLabels)
testFaceLabels = gender_encoder.transform(testFaceLabels)

age_encoder = LabelEncoder()
age_encoder.fit(trainAgeGroupLabels)
trainAgeGroupLabels = age_encoder.transform(trainAgeGroupLabels)
testAgeGroupLabels = age_encoder.transform(testAgeGroupLabels)

# ************ 9. KNN Model ************
# Train the model using the training sets
genderModel = KNeighborsClassifier(n_neighbors=1)
genderModel.fit(trainFaces, trainFaceLabels)
ageModel = KNeighborsClassifier(n_neighbors=1)
ageModel.fit(trainAgeGroupFaces, trainAgeGroupLabels)
newModel = load_model('c:/dl_research/age_gender_detection/models/facenet_keras.h5')
print('Model Loaded...')
def detect_age_gender_final(query_img):
    query_face_embedding = get_embedding(newModel, query_img)
    query_face_samples = expand_dims(query_face_embedding, axis=0)

    gender_class_label = genderModel.predict(query_face_samples)
    gender_face_prob = genderModel.predict_proba(query_face_samples)
    gender_class_index = gender_class_label[0]
    gender_class_probability = gender_face_prob[0,gender_class_index] * 100
    gender_predict = gender_encoder.inverse_transform(gender_class_label)
    
    age_class_label = ageModel.predict(query_face_samples)
    age_face_prob = ageModel.predict_proba(query_face_samples)
    age_class_index = age_class_label[0]
    age_class_probability = age_face_prob[0,age_class_index] * 100
    age_predict = age_encoder.inverse_transform(age_class_label)
    #print('Predicted: %s (%.2f)' % (query_predict_name[0], query_class_probability))
    gender = gender_predict[0]
    if gender == 'male':
        gender = 'Male'
    elif gender == 'female':
        gender = 'Female'
    age = age_predict[0]
    title = 'Predicted Gender:   [%s] \n Predicted Age Group:   %s' % (gender, age)
    return title

def run():
    root = Tk()
    root.filename = filedialog.askopenfilename(title='Pick up the image')
    root.withdraw()
    query_img, img = extract_face(root.filename)
    title = detect_age_gender_final(query_img)
    font = {'family' : 'Arial',
        'weight' : 'bold',
        'size'   : 26}
    pyplot.rc('font', **font)
    pyplot.figure(figsize=(10,10))
    pyplot.rcParams["figure.figsize"] = [7.50, 3.50]
    pyplot.rcParams["figure.autolayout"] = True
    pyplot.rcParams.update({'text.color': "blue",
                     'axes.labelcolor': "green"})
    pyplot.title(title);
    pyplot.imshow(img);
    pyplot.axis('off');

run()


def run_video(usercam=True):
    if usercam:
            cap = cv2.VideoCapture(0)
            ret, frame = cap.read()
            if ret:
                image = cv2.flip(frame, 1)
                cap.release()
            # Check if the webcam is opened correctly
                query_img = extract_face2(image)
                title = detect_age_gender_final(query_img)
                font = {'family' : 'Book Antiqua',
                        'weight' : 'bold',
                        'size'   : 24}
                pyplot.rc('font', **font)
                pyplot.rcParams["figure.figsize"] = [10, 10]
                pyplot.rcParams["figure.autolayout"] = True
                pyplot.rcParams.update({'text.color': "blue",
                     'axes.labelcolor': "green"})
                pyplot.title(title);
                pyplot.imshow(image[:, :, ::-1]);
                pyplot.axis('off');
            else:
                print("Can't Open Camera")
                sys.exit()

run_video()
